{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e9cac71-8ab2-4ae0-a7bb-f39ded67c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee5ef949-6dd2-4380-b44e-c033d0ac6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f9f4728-d8c8-4910-af6b-24cf5b27da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define data loaders\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f65653e-a9a6-443d-9188-9e22213c29d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CNN and move to GPU\n",
    "cnn_model = CNN()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_model = cnn_model.to(device)  # Move the initialized model to the GPU if available\n",
    "\n",
    "# Define criterion and optimizer for CNN\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4daad62f-038a-4786-931d-85c9a37e4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for evaluation metrics\n",
    "def calculate_metrics(predictions, true_labels):\n",
    "    accuracy = (predictions == true_labels).mean()\n",
    "    # Calculate F1 score (assuming binary classification for simplicity)\n",
    "    tp = ((predictions == 1) & (true_labels == 1)).sum()\n",
    "    fp = ((predictions == 1) & (true_labels == 0)).sum()\n",
    "    fn = ((predictions == 0) & (true_labels == 1)).sum()\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    return accuracy, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecf8d30-47c9-4c78-8449-ddd5ce7b042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN\n",
    "start_time_cnn = time.time()\n",
    "for epoch in range(5):  # Number of epochs\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer_cnn.zero_grad()\n",
    "        outputs = cnn_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_cnn.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/5] - Loss: {running_loss / len(trainloader)}\")\n",
    "\n",
    "end_time_cnn = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f199263-1d36-4ad3-9498-4ac43588ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of CNN\n",
    "# Calculate predictions\n",
    "predicted_labels_cnn = []\n",
    "true_labels_cnn = []\n",
    "loss_cnn = 0.0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = cnn_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_labels_cnn.extend(predicted.cpu().numpy())\n",
    "        true_labels_cnn.extend(labels.cpu().numpy())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_cnn += loss.item()\n",
    "\n",
    "accuracy_cnn, f1_score_cnn = calculate_metrics(np.array(predicted_labels_cnn), np.array(true_labels_cnn))\n",
    "loss_cnn /= len(testloader)\n",
    "\n",
    "print(\"CNN Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_cnn}\")\n",
    "print(f\"F1 Score: {f1_score_cnn}\")\n",
    "print(f\"Loss: {loss_cnn}\")\n",
    "print(f\"Training time: {end_time_cnn - start_time_cnn} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9fdc04-3f3e-42d4-bd40-ea12e44afd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained Faster R-CNN backbone (ResNet50) without the final classification layer\n",
    "faster_rcnn_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = faster_rcnn_model.roi_heads.box_predictor.cls_score.in_features\n",
    "faster_rcnn_model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, 10)  # Change the output layer to fit MNIST classes\n",
    "\n",
    "faster_rcnn_model = faster_rcnn_model.to(device)\n",
    "\n",
    "# Define criterion and optimizer for Faster R-CNN\n",
    "params = [p for p in faster_rcnn_model.parameters() if p.requires_grad]\n",
    "optimizer_faster_rcnn = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer_faster_rcnn, step_size=3, gamma=0.1)\n",
    "\n",
    "# Training Faster R-CNN\n",
    "start_time_faster_rcnn = time.time()\n",
    "for epoch in range(5):  # Number of epochs\n",
    "    faster_rcnn_model.train()\n",
    "    for images, targets in trainloader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = faster_rcnn_model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer_faster_rcnn.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer_faster_rcnn.step()\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    print(f\"Epoch [{epoch + 1}/5] - Loss: {losses.item()}\")\n",
    "\n",
    "end_time_faster_rcnn = time.time()\n",
    "\n",
    "# Evaluation of Faster R-CNN\n",
    "faster_rcnn_model.eval()\n",
    "predicted_labels_faster_rcnn = []\n",
    "true_labels_faster_rcnn = []\n",
    "with torch.no_grad():\n",
    "    for images, targets in testloader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        outputs = faster_rcnn_model(images)\n",
    "        for output in outputs:\n",
    "            predicted_labels_faster_rcnn.extend(output['labels'].cpu().numpy())\n",
    "        for target in targets:\n",
    "            true_labels_faster_rcnn.extend(target['labels'].cpu().numpy())\n",
    "\n",
    "accuracy_faster_rcnn, f1_score_faster_rcnn = calculate_metrics(np.array(predicted_labels_faster_rcnn), np.array(true_labels_faster_rcnn))\n",
    "\n",
    "print(\"Faster R-CNN Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_faster_rcnn}\")\n",
    "print(f\"F1 Score: {f1_score_faster_rcnn}\")\n",
    "print(f\"Training time: {end_time_faster_rcnn - start_time_faster_rcnn} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d25e2b-ba02-4ce9-87e9-c622d2cbb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16\n",
    "vgg_model = torchvision.models.vgg16(pretrained=True)\n",
    "vgg_model.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # Modify the first layer\n",
    "vgg_model.classifier[6] = nn.Linear(4096, 10)  # Change the output layer to fit MNIST classes\n",
    "\n",
    "# Freeze layers except for the final classifier\n",
    "for param in vgg_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vgg_model = vgg_model.to(device)\n",
    "\n",
    "# Define criterion and optimizer for VGG16\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_vgg = optim.Adam(vgg_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training VGG16\n",
    "start_time_vgg = time.time()\n",
    "for epoch in range(5):  # Number of epochs\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer_vgg.zero_grad()\n",
    "        outputs = vgg_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_vgg.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/5] - Loss: {running_loss / len(trainloader)}\")\n",
    "\n",
    "end_time_vgg = time.time()\n",
    "\n",
    "# Evaluation of VGG16\n",
    "predicted_labels_vgg = []\n",
    "true_labels_vgg = []\n",
    "loss_vgg = 0.0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = vgg_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_labels_vgg.extend(predicted.cpu().numpy())\n",
    "        true_labels_vgg.extend(labels.cpu().numpy())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_vgg += loss.item()\n",
    "\n",
    "accuracy_vgg, f1_score_vgg = calculate_metrics(np.array(predicted_labels_vgg), np.array(true_labels_vgg))\n",
    "loss_vgg /= len(testloader)\n",
    "\n",
    "print(\"VGG16 Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_vgg}\")\n",
    "print(f\"F1 Score: {f1_score_vgg}\")\n",
    "print(f\"Loss: {loss_vgg}\")\n",
    "print(f\"Training time: {end_time_vgg - start_time_vgg} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbed64f-4f7b-40b2-95db-8cf7402041da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained AlexNet\n",
    "alexnet_model = torchvision.models.alexnet(pretrained=True)\n",
    "alexnet_model.features[0] = nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2)  # Modify the first layer\n",
    "alexnet_model.classifier[6] = nn.Linear(4096, 10)  # Change the output layer to fit MNIST classes\n",
    "\n",
    "# Freeze layers except for the final classifier\n",
    "for param in alexnet_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "alexnet_model = alexnet_model.to(device)\n",
    "\n",
    "# Define criterion and optimizer for AlexNet\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_alexnet = optim.Adam(alexnet_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training AlexNet\n",
    "start_time_alexnet = time.time()\n",
    "for epoch in range(5):  # Number of epochs\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer_alexnet.zero_grad()\n",
    "        outputs = alexnet_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_alexnet.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/5] - Loss: {running_loss / len(trainloader)}\")\n",
    "\n",
    "end_time_alexnet = time.time()\n",
    "\n",
    "# Evaluation of AlexNet\n",
    "predicted_labels_alexnet = []\n",
    "true_labels_alexnet = []\n",
    "loss_alexnet = 0.0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = alexnet_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_labels_alexnet.extend(predicted.cpu().numpy())\n",
    "        true_labels_alexnet.extend(labels.cpu().numpy())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_alexnet += loss.item()\n",
    "\n",
    "accuracy_alexnet, f1_score_alexnet = calculate_metrics(np.array(predicted_labels_alexnet), np.array(true_labels_alexnet))\n",
    "loss_alexnet /= len(testloader)\n",
    "\n",
    "print(\"AlexNet Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_alexnet}\")\n",
    "print(f\"F1 Score: {f1_score_alexnet}\")\n",
    "print(f\"Loss: {loss_alexnet}\")\n",
    "print(f\"Training time: {end_time_alexnet - start_time_alexnet} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779921a8-eb44-4ba2-bff2-51157c6cca11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
